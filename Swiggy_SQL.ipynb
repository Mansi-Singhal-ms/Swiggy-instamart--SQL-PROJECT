{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84e0122f-f341-4183-81fe-838416c0d873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.43)\n",
      "Requirement already satisfied: pymysql in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sqlalchemy) (3.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from sqlalchemy) (4.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cryptography in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (45.0.7)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cryptography) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.14->cryptography) (2.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#code to connect phython with sql databse\n",
    "! pip install sqlalchemy pymysql\n",
    "! pip install cryptography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d22d0527-0a6e-43ec-b472-27efaa5d43f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "engine = create_engine('mysql+pymysql://root:password@localhost/swiggy_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbc89739-553f-4ca0-b8a0-96193bf12979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer in frequent shopper:\n",
      "   CustomerID   CustomerName\n",
      "0   CUST0002     Diya Patel\n",
      "1   CUST0004   Ananya Gupta\n",
      "2   CUST0007    Kabir Mehta\n",
      "3   CUST0009    Arjun Joshi\n",
      "4   CUST0011     Riya Verma\n",
      "5   CUST0015   Aadhya Singh\n",
      "6   CUST0018   Vivaan Kumar\n",
      "7   CUST0020    Ayaan Patel\n",
      "8   CUST0024     Krish Iyer\n",
      "9   CUST0026  Atharv Chavan\n"
     ]
    }
   ],
   "source": [
    "1.# Customers in the 'Frequent Shopper' segment\n",
    "    #CONCEPT: NORMAL FILTERING\n",
    "Frequent_shopper=\"\"\"\n",
    "Select CustomerID,CustomerName from customers \n",
    "where CustomerSegment = \"Frequent Shopper\"\n",
    "limit 10;\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(Frequent_shopper, engine)\n",
    "print(\"Customer in frequent shopper:\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96ea47bc-4558-461b-8980-ebfcffa064dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 6 months registered customers:\n",
      "      CustomerName RegistrationDate\n",
      "0     Kyra Mishra       2025-03-15\n",
      "1     Anika Reddy       2025-05-01\n",
      "2       Siya Bose       2025-06-10\n",
      "3   Saanvi Pillai       2025-07-01\n",
      "4      Zoya Singh       2025-07-05\n",
      "5  Myra Chaudhary       2025-07-10\n",
      "6     Rohan Mehra       2025-07-12\n",
      "7     Dhruv Patel       2025-07-15\n"
     ]
    }
   ],
   "source": [
    "2.#Last 6 months registered customers.\n",
    "    #CONCEPT:=DATE_SUB() FUNCTION, WHERE CONDITION USED\n",
    "Registered_Customers =\"\"\"\n",
    "SELECT CustomerName, RegistrationDate\n",
    "FROM CUSTOMERS\n",
    "WHERE RegistrationDate >= DATE_SUB(CURDATE(), INTERVAL 6 MONTH);\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(Registered_Customers, engine)\n",
    "print(\"Last 6 months registered customers:\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9653ff4-0fde-4b28-8ae0-f52b00888b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products with price range between 500 and 1000.:\n",
      "   PRODUCTID                                PRODUCTNAME  UNITPRICE\n",
      "0   PROD044      Pampers Active Baby Diapers M-size 46      699.0\n",
      "1   PROD045  Pedigree Adult Dog Food Chicken & Veg 3kg      740.0\n",
      "2   PROD088           MamyPoko Pants Diapers L-size 44      750.0\n",
      "3   PROD089          Whiskas Adult Cat Food Tuna 1.2kg      550.0\n",
      "4   PROD133            Borges Olive Oil Extra Light 1L      950.0\n",
      "5   PROD134                     Figaro Olive Oil 500ml      550.0\n",
      "6   PROD144    Drools Adult Dog Food Chicken & Egg 3kg      650.0\n",
      "7   PROD145             Huggies Wonder Pants M-size 42      650.0\n"
     ]
    }
   ],
   "source": [
    "3.# Products with price range between 500 and 1000.\n",
    "    ## CONCEPT: BETWEEN USED\n",
    "PRODUCTS=\"\"\"\n",
    "SELECT PRODUCTID,PRODUCTNAME ,UNITPRICE FROM PRODUCTS\n",
    "WHERE UNITPRICE BETWEEN 500 AND 1000;\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(PRODUCTS, engine)\n",
    "print(\"Products with price range between 500 and 1000.:\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff484146-6580-46dc-921c-b6b4ca09bfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product name contains milk:\n",
      "                        ProductName\n",
      "0      Amul Taaza Toned Milk 500ml\n",
      "1             Britannia Milk Bread\n",
      "2     Cadbury Dairy Milk Silk 150g\n",
      "3  Amul Gold Full Cream Milk 500ml\n"
     ]
    }
   ],
   "source": [
    "4.## Products whose name contains 'Milk'\n",
    "     #CONCEPT:- WILDCARD CHARACTER USED\n",
    "MILK_PRODUCTS=\"\"\"\n",
    "SELECT ProductName from products\n",
    "where ProductName like \"%%milk%%\";\n",
    "\"\"\"\n",
    "\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(MILK_PRODUCTS, engine)\n",
    "print(\"Product name contains milk:\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f86c52b-ed21-4945-9947-975c0815ddd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 oldest delivery partners:\n",
      "   DeliveryPartnerID      PartnerName    HireDate\n",
      "0             DP001       Ravi Kumar  2022-01-10\n",
      "1             DP002      Sunita Devi  2022-01-12\n",
      "2             DP003       Amit Singh  2022-01-15\n",
      "3             DP041  David Schwimmer  2022-01-20\n",
      "4             DP004     Pooja Sharma  2022-02-01\n"
     ]
    }
   ],
   "source": [
    "5.# Top 5 oldest delivery partners\n",
    "    #CONCEPT:FILTERING & SORTING\n",
    "OLDEST_DP=\"\"\"\n",
    "SELECT DeliveryPartnerID,PartnerName ,HireDate from delivery_partners\n",
    "order by hireDate asc\n",
    "limit 5;\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(OLDEST_DP, engine)\n",
    "print(\"Top 5 oldest delivery partners:\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7d20b5f-fac2-416b-b2ad-706dbcf53275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO. of delivery partners hired in each year:\n",
      "    HireYear  PartnerCount\n",
      "0      2022            27\n",
      "1      2023            12\n",
      "2      2024            11\n"
     ]
    }
   ],
   "source": [
    "6.#Count of delivery partners hired in each year. \n",
    "    #CONCEPT USED: GROUP BY , YEAR()FUNCTION , ORDER BY\n",
    "DP=\"\"\"\n",
    "SELECT \n",
    "    YEAR(HireDate) AS HireYear,\n",
    "    COUNT(DeliveryPartnerID) AS PartnerCount\n",
    "FROM DELIVERY_PARTNERS\n",
    "GROUP BY YEAR(HireDate)\n",
    "ORDER BY HireYear;\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(DP, engine)\n",
    "print(\"NO. of delivery partners hired in each year:\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92df08b1-ddcc-4692-81e1-b25fac693e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO. of orders per month :\n",
      "     MonthNumber  MonthName  TotalOrders\n",
      "0             1    January          100\n",
      "1             2   February           75\n",
      "2             3      March           97\n",
      "3             4      April           92\n",
      "4             5        May           91\n",
      "5             6       June          102\n",
      "6             7       July           50\n",
      "7             8     August           45\n",
      "8             9  September           43\n",
      "9            10    October           43\n",
      "10           11   November           52\n",
      "11           12   December           51\n"
     ]
    }
   ],
   "source": [
    "7.## count of orders per month (across all years)?\n",
    "    #CONCEPT USED: MONTH(),MONTHNAME(),GROUP BY \n",
    "ORDERS_PER_MONTH=\"\"\"\n",
    "SELECT \n",
    "    MONTH(OrderDate) AS MonthNumber,\n",
    "    MONTHNAME(OrderDate) AS MonthName,\n",
    "    COUNT(OrderID) AS TotalOrders\n",
    "FROM ORDER_TRANSACTIONS\n",
    "GROUP BY MONTH(OrderDate), MONTHNAME(OrderDate)\n",
    "ORDER BY MonthNumber;\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(ORDERS_PER_MONTH, engine)\n",
    "print(\"NO. of orders per month :\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f03660bb-c05c-4d48-9cfe-061040056091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAYEMENT_METHODS USED :\n",
      "   paymentmethodID PaymentMethodName  usagecount\n",
      "0           PAY05            Wallet         177\n",
      "1           PAY03        Debit Card         175\n",
      "2           PAY01               UPI         174\n",
      "3           PAY04               COD         169\n",
      "4           PAY02       Credit Card         146\n"
     ]
    }
   ],
   "source": [
    "8.## Which payment method is used most frequently?\n",
    "      #CONCEPTS USED: AGGGREAGATE FUNCTION, JOIN , GROUP BY,ORDER BY\n",
    "PAYEMENT_METHOD=\"\"\"\n",
    "Select\n",
    "   o.paymentmethodID,p.PaymentMethodName, count(*) as usagecount\n",
    "   from Payment_Methods as p \n",
    "   left join Order_Transactions as o\n",
    "   on p.paymentmethodID= o.paymentmethodID\n",
    "group by o.paymentmethodID,p.paymentmethodName\n",
    "order by usagecount Desc;\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(PAYEMENT_METHOD, engine)\n",
    "print(\"PAYEMENT_METHODS USED :\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fbcb3a0-038b-4e9f-b4f2-85078c98e22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products Availability in each category:\n",
      "              CategoryName  ProductCount\n",
      "0      Snacks & Beverages            26\n",
      "1     Fruits & Vegetables            21\n",
      "2                 Staples            20\n",
      "3           Personal Care            19\n",
      "4     Cleaning Essentials            17\n",
      "5           Dairy & Bread            12\n",
      "6       Bakery & Biscuits            12\n",
      "7   Instant & Frozen Food             9\n",
      "8               Baby Care             4\n",
      "9     Breakfast & Cereals             4\n",
      "10               Pet Care             3\n",
      "11       Masalas & Spices             3\n"
     ]
    }
   ],
   "source": [
    "9.## How many products are available in each category.\n",
    "         #CONCEPT USED: AGGGREAGATE FUNCTION, JOIN , GROUP BY,ORDER BY\n",
    "PRODUCTS=\"\"\"\n",
    "SELECT \n",
    "   C.CategoryName,count(productID) AS ProductCount\n",
    "   FROM CATEGORIES AS C \n",
    "   LEFT JOIN PRODUCTS AS P\n",
    "   ON C.CategoryID=p.CategoryID\n",
    " group by c.categoryName\n",
    " ORDER BY ProductCount DESC;\n",
    " \"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(PRODUCTS, engine)\n",
    "print(\"Products Availability in each category:\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e185ab5-ff0e-41c9-b894-4cffcb478926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stores with warehouse capacity less than the average:\n",
      "      StoreID  WarehouseCapacity\n",
      "0   STORE001              15000\n",
      "1   STORE004              12000\n",
      "2   STORE005              16000\n",
      "3   STORE006              14000\n",
      "4   STORE008              15000\n",
      "5   STORE009              13000\n",
      "6   STORE010              16000\n",
      "7   STORE011              14000\n",
      "8   STORE013              15000\n",
      "9   STORE015              16000\n",
      "10  STORE019              16000\n",
      "11  STORE021              15000\n",
      "12  STORE023              14000\n"
     ]
    }
   ],
   "source": [
    "10 ##Stores with warehouse capacity less than the average\n",
    "        #CONCEPT USED: SUBQUERY ,AGGGREAGATE FUNCTION\n",
    "STORES_CAP=\"\"\"\n",
    "SELECT StoreID, WarehouseCapacity\n",
    "FROM STORES\n",
    "WHERE WarehouseCapacity < (\n",
    "    SELECT AVG(WarehouseCapacity)\n",
    "    FROM STORES);\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(STORES_CAP, engine)\n",
    "print(\"Stores with warehouse capacity less than the average:\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31c1a3d6-fbf8-4213-80ed-f45e5b4b40b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delivery partners who have delivered more than 20 orders:\n",
      "   DeliveryPartnerID   PartnerName\n",
      "0             DP015   Arun Pillai\n",
      "1             DP018   Divya Singh\n",
      "2             DP039    Bobby Deol\n",
      "3             DP046  Jack Sparrow\n"
     ]
    }
   ],
   "source": [
    "11.## Delivery partners who have delivered more than 20 orders\n",
    "       ##Concept Used: SUBQUERY, GROUP BY ,HAVING,AGGGREAGATE FUNCTION\n",
    "DP=\"\"\"\n",
    "SELECT \n",
    "   DeliveryPartnerID ,PartnerName from Delivery_Partners\n",
    "   where DeliveryPartnerID IN (\n",
    "      Select DeliveryPartnerID FROM ORDER_TRANSACTIONS  \n",
    "\t  GROUP BY DeliveryPartnerID\n",
    "      HAVING COUNT(*) > 20);\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(DP, engine)\n",
    "print(\"Delivery partners who have delivered more than 20 orders:\\n\",  df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "114e5c82-f49b-4c45-8b7b-b1f60a6bc3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supplier provides the most revenue-generating products:\n",
      "              SupplierName  SupplierRevenue\n",
      "0        HUL Distributors        142986.92\n",
      "1  Fresh Vegetables Co-op        111235.47\n",
      "2          Amul Dairy Co.         76728.31\n",
      "3            P&G Supplies         68390.15\n",
      "4           ITC Logistics         64502.35\n"
     ]
    }
   ],
   "source": [
    "12.##.Top supplier provides the most revenue-generating products\n",
    "        ##Concept Used: JOINS, GROUP BY ,AGGGREAGATE FUNCTION\n",
    "supplier=\"\"\"\n",
    "SELECT \n",
    "    S.SupplierName,\n",
    "    ROUND(SUM(O.TotalPrice),2) AS SupplierRevenue\n",
    "    FROM SUPPLIERS AS S\n",
    "    LEFT JOIN PRODUCTS AS P \n",
    "    ON S.SupplierID = P.SupplierID\n",
    "    LEFT JOIN ORDER_TRANSACTIONS AS O \n",
    "    ON P.ProductID = O.ProductID\n",
    "GROUP BY S.SupplierName\n",
    "ORDER BY SupplierRevenue DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(supplier, engine)\n",
    "print(\"Supplier provides the most revenue-generating products:\\n\",  df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa27a48a-347c-4b04-97e0-b0e0d863fa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "products with high stock but low sales.:\n",
      "                       ProductName  StockQuantity  TotalSold\n",
      "0   Nestle Maggi 2-Minute Noodles           1200       37.0\n",
      "1   Lays India's Magic Masala 52g           1500        7.0\n",
      "2        Kurkure Masala Munch 90g           1300       26.0\n",
      "3        Top Ramen Masala Noodles           1100       22.0\n",
      "4  Bingo Mad Angles Achaari Masti           1400       78.0\n",
      "5     Balaji Wafers Simply Salted           1200       27.0\n",
      "6     Yippee Magic Masala Noodles           1150       23.0\n",
      "7        Uncle Chipps Spicy Treat           1450       41.0\n",
      "8                 Too Yumm Karare           1300       31.0\n"
     ]
    }
   ],
   "source": [
    "13.##Identify products with high stock but low sales.\n",
    "      #Concepts Used: COALESCE FUNCTION ,JOIN ,GROUP BY , HAVING CLAUSE\n",
    "PRODUCTS=\"\"\"\n",
    "SELECT \n",
    "   P.ProductName,P.StockQuantity,\n",
    "   COALESCE(SUM(O.Quantity), 0) AS TotalSold\n",
    "FROM PRODUCTS AS P\n",
    "LEFT JOIN ORDER_TRANSACTIONS AS O \n",
    "ON P.ProductID = O.ProductID\n",
    "GROUP BY P.ProductName, P.StockQuantity\n",
    "HAVING TotalSold < 200 AND P.StockQuantity > 1000;\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(PRODUCTS, engine)\n",
    "print(\"products with high stock but low sales.:\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "585be65c-c10e-4f01-8f92-a667323ac990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cities with high order cancellations:\n",
      "     CityName  CancelledOrders\n",
      "0    Lucknow               22\n",
      "1  New Delhi               20\n",
      "2  Bengaluru               20\n",
      "3  Hyderabad               14\n",
      "4     Mumbai               12\n",
      "5  Ahmedabad               10\n",
      "6   Gurugram               10\n",
      "7      Noida                8\n",
      "8    Kolkata                7\n",
      "9     Jaipur                6\n"
     ]
    }
   ],
   "source": [
    "14.## Cities with high order cancellations\n",
    "        ##CONCEPT USED: JOINS, GROUP BY \n",
    "CITIES=\"\"\"\n",
    "SELECT \n",
    "    A.CityName,\n",
    "    COUNT(*) AS CancelledOrders\n",
    "    FROM ORDER_TRANSACTIONS AS O\n",
    "    LEFT JOIN CUSTOMERS AS C ON O.CustomerID = C.CustomerID\n",
    "    LEFT JOIN ADDRESS AS A ON C.AddressID = A.AddressID\n",
    "WHERE O.OrderStatus = 'Cancelled'\n",
    "GROUP BY A.CityName\n",
    "ORDER BY CancelledOrders DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(CITIES, engine)\n",
    "print(\"Cities with high order cancellations:\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af7c41db-4a4d-4a16-a3e8-8203a3fa88eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer segment contributing most to revenue:\n",
      "     CustomerSegment RevenueGenerated\n",
      "0        High Value           398.9K\n",
      "1  Frequent Shopper           388.2K\n",
      "2          New User           273.1K\n",
      "3            Lapsed           126.3K\n"
     ]
    }
   ],
   "source": [
    "15.## Customer segment contributing most to revenue.\n",
    "          ##CONCEPT USED:JOINS, GROUP BY,CONTACTENATION REPRESENTATION \n",
    "CUSTOMER_SEGMENT=\"\"\"\n",
    "SELECT \n",
    "    C.CustomerSegment,\n",
    "    CONCAT(ROUND(SUM(O.TotalPrice)/1000 , 1), 'K') AS RevenueGenerated\n",
    "FROM ORDER_TRANSACTIONS O\n",
    "JOIN CUSTOMERS C ON O.CustomerID = C.CustomerID\n",
    "GROUP BY C.CustomerSegment\n",
    "ORDER BY RevenueGenerated DESC;\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(CUSTOMER_SEGMENT, engine)\n",
    "print(\"Customer segment contributing most to revenue:\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b42d2b4f-a587-402c-9798-fab2e91c819f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 most expensive products in each category.:\n",
      "                                   ProductName CategoryID  UnitPrice  rn\n",
      "0                        Imported Avocado 1pc     CAT001      250.0   1\n",
      "1                       Fresh Pomegranate 1kg     CAT001      220.0   2\n",
      "2                          Fresh Broccoli 1pc     CAT002       70.0   1\n",
      "3                         Fresh Capsicum 500g     CAT002       60.0   2\n",
      "4            Epigamia Greek Yogurt Strawberry     CAT003       45.0   1\n",
      "5                         Nestle a+ Curd 400g     CAT003       42.0   2\n",
      "6                            Amul Butter 500g     CAT004      275.0   1\n",
      "7                     Amul Cheese Slices 100g     CAT004       78.0   2\n",
      "8                    English Oven Brown Bread     CAT005       55.0   1\n",
      "9                       Britannia Brown Bread     CAT005       50.0   2\n",
      "10                 Haldirams Aloo Bhujia 200g     CAT006       55.0   1\n",
      "11                                Ganesh Bhel     CAT006       45.0   2\n",
      "12      Raw Pressery Cold Pressed Juice 250ml     CAT007      150.0   1\n",
      "13             Tropicana 100% Orange Juice 1L     CAT007      140.0   2\n",
      "14                 Blue Tokai Coffee Roasters     CAT008      450.0   1\n",
      "15                Nescafe Classic Coffee 100g     CAT008      315.0   2\n",
      "16         Ashirvaad Select Sharbati Atta 5kg     CAT009      290.0   1\n",
      "17            Pillsbury Chakki Fresh Atta 5kg     CAT009      280.0   2\n",
      "18        India Gate Basmati Rice Classic 1kg     CAT010      220.0   1\n",
      "19              Organic Tattva Brown Rice 1kg     CAT010      150.0   2\n",
      "20             24 Mantra Organic Toor Dal 1kg     CAT011      210.0   1\n",
      "21                  Tata Sampann Toor Dal 1kg     CAT011      160.0   2\n",
      "22            Borges Olive Oil Extra Light 1L     CAT012      950.0   1\n",
      "23                     Figaro Olive Oil 500ml     CAT012      550.0   2\n",
      "24                 Gillette Mach3 Turbo Razor     CAT013      299.0   1\n",
      "25        Vaseline Intensive Care Body Lotion     CAT013      250.0   2\n",
      "26     Head & Shoulders Anti-Dandruff Shampoo     CAT014      195.0   1\n",
      "27             Dove Daily Shine Shampoo 180ml     CAT014      190.0   2\n",
      "28        Listerine Cool Mint Mouthwash 250ml     CAT015      149.0   1\n",
      "29         Sensodyne Fresh Gel Toothpaste 75g     CAT015      130.0   2\n",
      "30                   Ariel Matic Top Load 1kg     CAT016      250.0   1\n",
      "31      Comfort After Wash Fabric Conditioner     CAT016      220.0   2\n",
      "32              Vim Dishwash Liquid Gel 500ml     CAT017      105.0   1\n",
      "33                          Pril Dishwash Bar     CAT017       25.0   2\n",
      "34           Lizol Floor Cleaner Citrus 975ml     CAT018      193.0   1\n",
      "35         Harpic Powerplus Toilet Cleaner 1L     CAT018      185.0   2\n",
      "36                 Del Monte Penne Pasta 500g     CAT019      120.0   1\n",
      "37                  Veeba Pasta & Pizza Sauce     CAT019       99.0   2\n",
      "38           ITC Master Chef Frozen Peas 500g     CAT020      125.0   1\n",
      "39                         McCain Smiles 415g     CAT020      115.0   2\n",
      "40           MamyPoko Pants Diapers L-size 44     CAT021      750.0   1\n",
      "41      Pampers Active Baby Diapers M-size 46     CAT021      699.0   2\n",
      "42  Pedigree Adult Dog Food Chicken & Veg 3kg     CAT022      740.0   1\n",
      "43    Drools Adult Dog Food Chicken & Egg 3kg     CAT022      650.0   2\n",
      "44                       MDH Deggi Mirch 100g     CAT023       72.0   1\n",
      "45                 Catch Turmeric Powder 200g     CAT023       65.0   2\n",
      "46                  Kelloggs Corn Flakes 875g     CAT024      360.0   1\n",
      "47                            Quaker Oats 1kg     CAT024      199.0   2\n",
      "48                 Lindt Excellence 90% Cocoa     CAT025      450.0   1\n",
      "49              Hersheys Chocolate Syrup 623g     CAT025      250.0   2\n"
     ]
    }
   ],
   "source": [
    "16.##Top 2 most expensive products in each category.\n",
    "      ###ConceptUse: WINDOW FUNCTION :- ROW_NUMBER, CTE\n",
    "\n",
    "EXPENSIVE_PRODUCTS=\"\"\"\n",
    "WITH RankedProducts AS (\n",
    "    SELECT \n",
    "        ProductName,\n",
    "        CategoryID,\n",
    "        UnitPrice,\n",
    "        ROW_NUMBER() OVER (PARTITION BY CategoryID ORDER BY UnitPrice DESC) AS rn\n",
    "    FROM PRODUCTS\n",
    ")\n",
    "SELECT * \n",
    "FROM RankedProducts\n",
    "WHERE rn <= 2;\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(EXPENSIVE_PRODUCTS, engine)\n",
    "print(\"Top 2 most expensive products in each category.:\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53abdf53-3b75-4db7-817b-93c4f5773134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank delivery partners by number of orders handled.:\n",
      "    DeliveryPartnerID      PartnerName  TotalOrders  PartnerRank\n",
      "0              DP015      Arun Pillai           31            1\n",
      "1              DP046     Jack Sparrow           28            2\n",
      "2              DP018      Divya Singh           26            3\n",
      "3              DP039       Bobby Deol           23            4\n",
      "4              DP047           Kramer           20            5\n",
      "5              DP017    Chetan Bhagat           20            5\n",
      "6              DP001       Ravi Kumar           20            5\n",
      "7              DP042    Elena Gilbert           20            5\n",
      "8              DP022      Harish Iyer           20            5\n",
      "9              DP032      Tina Ambani           20            5\n",
      "10             DP010      Manoj Kumar           19            6\n",
      "11             DP004     Pooja Sharma           19            6\n",
      "12             DP019       Esha Gupta           19            6\n",
      "13             DP041  David Schwimmer           19            6\n",
      "14             DP027    Nisha Agarwal           19            6\n",
      "15             DP030     Rani Mukerji           18            7\n",
      "16             DP043   Fiona Glenanne           18            7\n",
      "17             DP031      Sanjay Dutt           18            7\n",
      "18             DP012    Ganesh Murthy           18            7\n",
      "19             DP033       Usha Uthup           18            7\n",
      "20             DP005     Suresh Patel           18            7\n",
      "21             DP002      Sunita Devi           18            7\n",
      "22             DP037      Zeenat Aman           18            7\n",
      "23             DP013   Vikram Rathore           18            7\n",
      "24             DP003       Amit Singh           18            7\n",
      "25             DP035      Wasim Akram           17            8\n",
      "26             DP028    Omar Abdullah           17            8\n",
      "27             DP008     Rajesh Gupta           17            8\n",
      "28             DP021       Gauri Khan           17            8\n",
      "29             DP050   Naruto Uzumaki           16            9\n",
      "30             DP006     Deepak Yadav           16            9\n",
      "31             DP044  George Costanza           16            9\n",
      "32             DP048     Lisa Simpson           16            9\n",
      "33             DP036     Yusuf Pathan           16            9\n",
      "34             DP020       Farhan Ali           15           10\n",
      "35             DP049    Michael Scott           15           10\n",
      "36             DP009     Anjali Verma           15           10\n",
      "37             DP038      Anil Kapoor           14           11\n",
      "38             DP040    Chandler Bing           13           12\n",
      "39             DP016      Bhavna Shah           13           12\n",
      "40             DP045    Homer Simpson           12           13\n",
      "41             DP011     Laxmi Prasad           12           13\n",
      "42             DP007     Meena Kumari           12           13\n",
      "43             DP014      Sneha Reddy           12           13\n",
      "44             DP024    Jaya Bachchan           12           13\n",
      "45             DP029      Prakash Raj           11           14\n",
      "46             DP025      Karan Johar           10           15\n",
      "47             DP023      Imran Pasha            9           16\n",
      "48             DP034     Vivek Oberoi            8           17\n",
      "49             DP026      Mahesh Babu            7           18\n"
     ]
    }
   ],
   "source": [
    "18.##Rank delivery partners by number of orders handled.\n",
    "        ## CONCEPT USED:- WINDOW FUNCTION(DENSE RANK),JOIN, AGGREGATE FUNCTION,GROUP BY \n",
    "DP=\"\"\"\n",
    "SELECT \n",
    "    DP.DeliveryPartnerID,\n",
    "    DP.PartnerName,\n",
    "    COUNT(OT.OrderID) AS TotalOrders,\n",
    "    dense_rank() OVER (ORDER BY COUNT(OT.OrderID) DESC) AS PartnerRank\n",
    "FROM DELIVERY_PARTNERS DP\n",
    "JOIN ORDER_TRANSACTIONS OT ON DP.DeliveryPartnerID = OT.DeliveryPartnerID\n",
    "GROUP BY DP.DeliveryPartnerID, DP.PartnerName;\n",
    "\"\"\"\n",
    "\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(DP, engine)\n",
    "print(\"Rank delivery partners by number of orders handled.:\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a96ae159-5773-42b4-a8aa-93c6a4b9a120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorize products:\n",
      "     ProductID                            ProductName CategoryID  \\\n",
      "0     PROD001            Amul Taaza Toned Milk 500ml     CAT003   \n",
      "1     PROD002                   Britannia Milk Bread     CAT005   \n",
      "2     PROD003          Nestle Maggi 2-Minute Noodles     CAT019   \n",
      "3     PROD004                  Tata Salt Iodized 1kg     CAT012   \n",
      "4     PROD005     Ashirvaad Select Sharbati Atta 5kg     CAT009   \n",
      "..        ...                                    ...        ...   \n",
      "145   PROD146                Himalaya Baby Wipes 72s     CAT021   \n",
      "146   PROD147  Comfort After Wash Fabric Conditioner     CAT016   \n",
      "147   PROD148        Vanish Oxi Action Stain Remover     CAT016   \n",
      "148   PROD149         Baygon All Insect Killer Spray     CAT018   \n",
      "149   PROD150     Duracell Ultra AA Batteries 4-pack     CAT018   \n",
      "\n",
      "     StockQuantity StockCategory  \n",
      "0              500  Medium Stock  \n",
      "1              300  Medium Stock  \n",
      "2             1200    High Stock  \n",
      "3              800  Medium Stock  \n",
      "4              250  Medium Stock  \n",
      "..             ...           ...  \n",
      "145            300  Medium Stock  \n",
      "146            350  Medium Stock  \n",
      "147            300  Medium Stock  \n",
      "148            400  Medium Stock  \n",
      "149            500  Medium Stock  \n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "18.#Categorize products as 'Low Stock', 'Medium Stock', or 'High Stock'.\n",
    "         ##CONCEPT USED: CASE STATEMENT \n",
    "\n",
    "PRODUCTS=\"\"\"\n",
    "SELECT \n",
    "    ProductID,\n",
    "    ProductName,\n",
    "    CategoryID,\n",
    "    StockQuantity,\n",
    "    CASE\n",
    "       WHEN StockQuantity < 200 then 'Low Stock'\n",
    "       WHEN StockQuantity BETWEEN 200 AND 800 THEN 'Medium Stock'\n",
    "       ELSE 'High Stock'\n",
    "\tEND AS StockCategory\n",
    "    from Products;\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(PRODUCTS, engine)\n",
    "print(\"Categorize products:\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f4d22bf-35f5-4065-900a-ff0ab5ab3499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average delivery time per city ranking :\n",
      "        CityName  AvgDeliveryTime  CityRank\n",
      "0       Chennai            16.25         1\n",
      "1     Mangaluru            16.50         2\n",
      "2     Bengaluru            17.19         3\n",
      "3   Bhubaneswar            18.60         4\n",
      "4         Kochi            18.67         5\n",
      "5        Jaipur            19.00         6\n",
      "6          Pune            19.67         7\n",
      "7       Lucknow            19.67         7\n",
      "8        Mumbai            19.86         8\n",
      "9     New Delhi            19.89         9\n",
      "10        Patna            20.00        10\n",
      "11   Chandigarh            20.00        10\n",
      "12       Bhopal            20.50        11\n",
      "13    Hyderabad            20.56        12\n",
      "14    Ahmedabad            21.25        13\n",
      "15     Gurugram            21.36        14\n",
      "16        Noida            22.50        15\n",
      "17       Mysuru            23.00        16\n",
      "18   Coimbatore            23.50        17\n",
      "19      Kolkata            24.67        18\n"
     ]
    }
   ],
   "source": [
    "19.##Average delivery time per city and rank them.\n",
    "      ##CONCEPT USED:- WINDOW FUNCTION(),AGGEGATE FUNCTION, JOINS, GROUP BY \n",
    "DELIVERY_TIME=\"\"\"\n",
    "SELECT \n",
    "    A.CityName,\n",
    "    ROUND(AVG(OT.DeliveryTimeMinutes), 2) AS AvgDeliveryTime,\n",
    "    DENSE_RANK() OVER (ORDER BY AVG(OT.DeliveryTimeMinutes) ASC) AS CityRank\n",
    "FROM ORDER_TRANSACTIONS AS OT\n",
    "LEFT JOIN DELIVERY_PARTNERS AS DP \n",
    "    ON OT.DeliveryPartnerID = DP.DeliveryPartnerID\n",
    "LEFT JOIN ADDRESS AS A \n",
    "   ON DP.AddressID = A.AddressID\n",
    "WHERE OT.OrderStatus = 'Delivered'\n",
    "GROUP BY A.CityName;\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(DELIVERY_TIME, engine)\n",
    "print(\"Average delivery time per city ranking :\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "803671c8-d0c7-46cd-a2a5-3897c112c929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of customers on the total amount they've spent. :\n",
      "    CustomerID    CustomerName  TotalSpent  SpendingRank\n",
      "0    CUST0038  Myra Chaudhary    42272.94             1\n",
      "1    CUST0017     Anika Reddy    42094.93             2\n",
      "2    CUST0042     Aditi Gupta    37813.24             3\n",
      "3    CUST0032      Zoya Singh    36276.60             4\n",
      "4    CUST0048     Anaya Kumar    36042.03             5\n",
      "5    CUST0040     Tara Khanna    35612.61             6\n",
      "6    CUST0006    Saanvi Reddy    34549.77             7\n",
      "7    CUST0049      Veer Singh    32610.89             8\n",
      "8    CUST0003    Vihaan Singh    32132.91             9\n",
      "9    CUST0001    Aarav Sharma    31852.47            10\n",
      "10   CUST0002      Diya Patel    30524.18            11\n",
      "11   CUST0014    Shaurya Nair    29332.38            12\n",
      "12   CUST0045    Aryan Sharma    27990.09            13\n",
      "13   CUST0026   Atharv Chavan    27387.66            14\n",
      "14   CUST0012  Ishaan Agarwal    27288.88            15\n",
      "15   CUST0036         Eva Ali    27203.35            16\n",
      "16   CUST0023       Siya Bose    26915.13            17\n",
      "17   CUST0025      Anvi Desai    26630.34            18\n",
      "18   CUST0018    Vivaan Kumar    25453.05            19\n",
      "19   CUST0004    Ananya Gupta    23447.48            20\n",
      "20   CUST0022      Neel Menon    23405.37            21\n",
      "21   CUST0021       Pari Jain    23121.07            22\n",
      "22   CUST0041     Arjun Reddy    23090.90            23\n",
      "23   CUST0033       Kabir Das    22540.46            24\n",
      "24   CUST0034      Ira Saxena    22454.02            25\n",
      "25   CUST0030      Yash Mehta    22443.07            26\n",
      "26   CUST0043     Rohan Mehra    22188.96            27\n",
      "27   CUST0009     Arjun Joshi    22177.00            28\n",
      "28   CUST0046    Ishita Verma    22064.80            29\n",
      "29   CUST0037    Rudra Pandey    21553.00            30\n",
      "30   CUST0035      Dev Sharma    20558.59            31\n",
      "31   CUST0029      Navya Bhat    20522.91            32\n",
      "32   CUST0031    Aarohi Kumar    20428.47            33\n",
      "33   CUST0007     Kabir Mehta    20276.82            34\n",
      "34   CUST0008       Myra Shah    20118.91            35\n",
      "35   CUST0027   Saanvi Pillai    19822.29            36\n",
      "36   CUST0010       Zara Khan    19039.24            37\n",
      "37   CUST0047     Dhruv Patel    16607.08            38\n",
      "38   CUST0039       Sai Joshi    16532.24            39\n",
      "39   CUST0024      Krish Iyer    15937.62            40\n",
      "40   CUST0019    Kiara Sharma    15434.29            41\n",
      "41   CUST0050    Samaira Khan    15419.31            42\n",
      "42   CUST0020     Ayaan Patel    15079.49            43\n",
      "43   CUST0015    Aadhya Singh    14742.51            44\n",
      "44   CUST0013     Kyra Mishra    14695.67            45\n",
      "45   CUST0016   Reyansh Gupta    14172.23            46\n",
      "46   CUST0044    Khushi Singh    14084.75            47\n",
      "47   CUST0028       Arnav Rao    13993.18            48\n",
      "48   CUST0005     Advik Kumar    12083.85            49\n",
      "49   CUST0011      Riya Verma     8533.43            50\n"
     ]
    }
   ],
   "source": [
    "20.##Ranking customers based on the total amount they've spent.\n",
    "        ##CONCEPT USED: CTE, WINDOW FUNCTION\n",
    "Customer_Ranking=\"\"\"\n",
    "WITH CustomerSpending AS (\n",
    "    SELECT \n",
    "        CustomerID,\n",
    "        Round(SUM(TotalPrice),2) AS TotalSpent\n",
    "    FROM ORDER_TRANSACTIONS\n",
    "    GROUP BY CustomerID\n",
    "),\n",
    "RankedCustomers AS (\n",
    "    SELECT \n",
    "        cs.CustomerID,\n",
    "        c.CustomerName,\n",
    "        cs.TotalSpent,\n",
    "        RANK() OVER (ORDER BY cs.TotalSpent DESC) AS SpendingRank\n",
    "    FROM CustomerSpending AS cs\n",
    "    LEFT JOIN CUSTOMERS AS c ON cs.CustomerID = c.CustomerID\n",
    ")\n",
    "SELECT * \n",
    "FROM RankedCustomers\n",
    "ORDER BY SpendingRank;\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(Customer_Ranking, engine)\n",
    "print(\"Rank of customers on the total amount they've spent. :\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f705e82b-0af0-43fb-af55-71579d06febb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers who placed an order but never received a order :\n",
      "   CustomerID CustomerName CurrentOrderStatus\n",
      "0   CUST0029   Navya Bhat           Returned\n",
      "1   CUST0010    Zara Khan            Shipped\n",
      "2   CUST0007  Kabir Mehta            Pending\n"
     ]
    }
   ],
   "source": [
    "21.##Customers who placed an order but never received it (order status not 'Delivered').\n",
    "        ##CONCEPT USED: CTE, WINDOW FUNCTION ,JOINS,CASE STATEMENTS\n",
    "NOT_DELIVERED=\"\"\"\n",
    "WITH OrderStatusSummary AS (\n",
    "    SELECT \n",
    "        CustomerID,\n",
    "        MAX(CASE WHEN OrderStatus = 'Delivered' THEN 1 ELSE 0 END) AS HasDeliveredOrder\n",
    "    FROM ORDER_TRANSACTIONS\n",
    "    GROUP BY CustomerID\n",
    "),\n",
    "LatestOrders AS (\n",
    "    SELECT \n",
    "        ot.CustomerID,\n",
    "        ot.OrderStatus,\n",
    "        ROW_NUMBER() OVER (PARTITION BY ot.CustomerID ORDER BY ot.OrderDate DESC) AS row_num\n",
    "    FROM ORDER_TRANSACTIONS AS ot)\n",
    "SELECT \n",
    "    c.CustomerID,\n",
    "    c.CustomerName,\n",
    "    lo.OrderStatus AS CurrentOrderStatus\n",
    "FROM OrderStatusSummary AS oss\n",
    "JOIN CUSTOMERS AS c ON c.CustomerID = oss.CustomerID\n",
    "JOIN LatestOrders AS lo ON c.CustomerID = lo.CustomerID AND lo.row_num = 1\n",
    "WHERE oss.HasDeliveredOrder = 0;\n",
    "\"\"\"\n",
    "# Use Pandas to run query and get table\n",
    "df = pd.read_sql(NOT_DELIVERED, engine)\n",
    "print(\"Customers who placed an order but never received a order :\\n\",  df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c9f17-dd30-4f7a-9c97-5187c2d40686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
